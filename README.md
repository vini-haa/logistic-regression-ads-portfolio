# Projeto de Classifica√ß√£o: Previs√£o de Cliques em An√∫ncios Online

## üìÑ Sum√°rio

Este projeto de portf√≥lio demonstra um fluxo completo de Machine Learning, desde a prepara√ß√£o dos dados at√© a avalia√ß√£o comparativa de modelos, para prever se um usu√°rio de internet clicar√° em um an√∫ncio. O modelo campe√£o, uma **Regress√£o Log√≠stica** otimizada, alcan√ßou um **AUC (Area Under the Curve) de 0.998**, provando ser uma solu√ß√£o robusta, precisa e, crucialmente, interpret√°vel para resolver o problema de neg√≥cio.

---

## üéØ Contexto e Objetivo de Neg√≥cio

O objetivo deste projeto √© desenvolver um modelo de classifica√ß√£o bin√°ria que responda √† pergunta: **"Com base no perfil e comportamento de um usu√°rio, qual a probabilidade de ele clicar em um an√∫ncio online?"**

Uma solu√ß√£o eficaz para este problema permite que equipes de marketing digital otimizem o retorno sobre o investimento (ROI) em campanhas, direcionando an√∫ncios de forma mais inteligente e personalizando o conte√∫do para perfis com maior propens√£o √† convers√£o.

---

## üõ†Ô∏è Metodologia

O projeto foi estruturado seguindo as melhores pr√°ticas de um ciclo de vida de Data Science, dividido em dois notebooks principais.

### 1. Prepara√ß√£o de Dados e Engenharia de Features (`01_data_preparation.ipynb`)

O trabalho come√ßou com o dataset `advertising.csv`. A etapa de prepara√ß√£o incluiu:
* **Limpeza de Dados:** Remo√ß√£o de colunas com alta cardinalidade que poderiam prejudicar a performance do modelo, como `Ad Topic Line`, `City`, e `Country`.
* **Engenharia de Features:** A coluna `Timestamp` foi transformada para extrair features temporais (`Hour`, `DayOfWeek`, `Month`), permitindo que o modelo aprendesse com padr√µes baseados em quando o usu√°rio interagia com o site.

### 2. An√°lise, Modelagem e Avalia√ß√£o (`02_logistic_regression_analysis.ipynb`)

Com os dados limpos, o segundo notebook focou na an√°lise e modelagem.

#### An√°lise Explorat√≥ria de Dados (EDA)

Foram geradas visualiza√ß√µes para entender a rela√ß√£o entre as features e a vari√°vel alvo (`Clicked on Ad`).

![Boxplots das Features Chave vs. Clique](/images/feature_boxplots.png)
*Gr√°fico gerado a partir do notebook `02_logistic_regression_analysis.ipynb`.*

A an√°lise dos boxplots acima revelou tend√™ncias muito claras:
* **Idade (`Age`):** Usu√°rios que clicaram no an√∫ncio (`Clicked on Ad = 1`) tendem a ser mais velhos.
* **Tempo no Site e na Internet:** Usu√°rios que clicam passam, em m√©dia, significativamente menos tempo tanto no site (`Daily Time Spent on Site`) quanto na internet em geral (`Daily Internet Usage`).

#### Modelagem e Otimiza√ß√£o

* **Modelo Baseline:** A Regress√£o Log√≠stica foi escolhida como o modelo inicial por sua efici√™ncia e alta interpretabilidade.
* **Pipeline e Otimiza√ß√£o:** Para garantir a robustez e a compara√ß√£o justa, todos os modelos foram treinados dentro de um `Pipeline` que inclu√≠a a padroniza√ß√£o dos dados (`StandardScaler`). O `GridSearchCV` foi aplicado para encontrar os melhores hiperpar√¢metros para a Regress√£o Log√≠stica.

#### An√°lise de Interpretabilidade (SHAP)

Para entender *por que* o modelo toma suas decis√µes, foi utilizada a biblioteca SHAP.

![Gr√°fico de Barras SHAP](images\shap_summary_plot_beeswarm.png)
*Gr√°fico gerado a partir do notebook `02_logistic_regression_analysis.ipynb`.*

O gr√°fico de barras SHAP confirmou as descobertas da EDA de forma quantitativa. Ele mostra que o tempo de uso da internet e o tempo no site s√£o os fatores de maior impacto, seguidos pela idade do usu√°rio.

#### Benchmarking

Para validar a escolha do modelo, a performance da Regress√£o Log√≠stica otimizada foi comparada com outros dois algoritmos poderosos: `Random Forest` e `XGBoost`.

---

## üìà Resultados

O processo de benchmarking demonstrou que a **Regress√£o Log√≠stica** n√£o apenas foi o modelo mais simples, mas tamb√©m o que apresentou a melhor performance geral.

### Tabela Comparativa dos Modelos

| Modelo | AUC | Accuracy |
| :--- | :---: | :---: |
| **Logistic Regression** | **0.9980** | **0.9733** |
| Random Forest | 0.9947 | 0.9567 |
| XGBoost | 0.9882 | 0.9467 |

*Tabela de resultados gerada pelo notebook `02_logistic_regression_analysis.ipynb`.*

### Desempenho do Modelo Campe√£o

O desempenho detalhado da Regress√£o Log√≠stica no conjunto de teste √© apresentado no relat√≥rio e na matriz de confus√£o abaixo.

```text
--- Relat√≥rio de Classifica√ß√£o: Regress√£o Log√≠stica ---
              precision    recall  f1-score   support
           0       0.95      1.00      0.98       157
           1       1.00      0.94      0.97       143

    accuracy                           0.97       300
   macro avg       0.98      0.97      0.97       300
weighted avg       0.97      0.97      0.97       300